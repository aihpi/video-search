# LLM Configuration

# Backend selection: "ollama" or "vllm"
LLM_BACKEND=ollama

# Model to use (Ollama format)
LLM_MODEL=qwen3:8b
# Ollama configuration (for local development)
OLLAMA_BASE_URL=http://localhost:11434/v1

# vLLM configuration (for production)
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_API_KEY=vllm

# Other existing configurations
EMBEDDING_MODEL_NAME=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
CHROMA_DB_DIR=chroma_db
COLLECTION_NAME=transcript_embeddings